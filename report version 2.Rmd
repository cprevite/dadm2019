--- 
title: 'Report: Data Analytics for Decision Making'
author: "Claudio Previte and Ana -Maria Casian"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: TRUE
    toc_float:
      collapsed: true
      smooth_scroll: true
    fig_caption: yes
    code_folding: hide 
---

<style>
body {
text-align: justify}
</style> 


```{r, message=FALSE, warning=FALSE}
library(here)
library(Hmisc)
library(dplyr)
library(DataExplorer)
library(ggplot2)
library(lattice)
library(inspectdf)
library(kableExtra)
library(explore)
library(DT)
library(dplyr)
library(Boruta)
library(corrr)
library(tidyverse)
library(caret)
library(randomForest)
library(funModeling)
library(gmodels)
library(data.table)
library(DMwR)

```

# Introduction

Data science is gaining more ground in this day and age and decision making based on machine learning algorithms is a big part of it. It intends to assist the user in taking fast and smart decision in an era where time management stands as a competitive advantage and minimising risks, monetary or reputational, are the pinnacle for the success. Would a machine learning algorithm be able to predict the RTD Tea drinks consumption in Spain? What are the factors that are driving the consumption? Are they the same in the neighbourhood country? This report will
answer these questions and touch upon new discussions. The paper is built in two parts. The first one is an introduction to the background of the topic, an overview of the data sources and of the data manipulation. The second part consists of the analysis of the data, the statistical models used and the final discussion

- purpose of the course
- the benefit of Machine Learning in general



## Case description

- describe the problem
- benefit of Machine Learning in this special case


Quality issues related to the final products have been dected within the printing company.  During the print run process, grooves are sometimes formed in the cylinder, which leads to a product with defects, that cannot be provided to the customer. Moreover, when this type of quality related problem is detected, the run is suspended and the cylinder has to be removed and fixed before using it again in production. This event  disrupts the manufacturing process thus raising the risk of delaying the delivery date of the costumer order, but also translats im the fact that the efficiency of the whole operation is slowed down by turning off production, removing the cylinder and replacing it. These factors in turn decrease profits, as the machine is not producing as many final products as it should be and the employees are payed for idle time. Moreover, the costs increase as repair costs occur.

Given the situation described again, the company has decided to investigate why the defects are generated during the runs. For this, the firm has gather data on 512 observations. The atttributes that describe these data points are mounting 40, out of which 20 attributes are numeric and 20 are nominal.The variable of interest is represented by the class band type, which in turn is formed by 312 instances of "no band" and 200 instances of "band".


```{r,  echo = FALSE, warning = FALSE, message = FALSE, out.width = "700px"}

knitr::include_graphics("C:/Users/claud/Desktop/Ana/HEC/3rd semester/Projects in Data Analytics/project/dadm2019/pictures/attributes1.PNG")

```

```{r,  echo = FALSE, warning = FALSE, message = FALSE, out.width = "700px"}

knitr::include_graphics("C:/Users/claud/Desktop/Ana/HEC/3rd semester/Projects in Data Analytics/project/dadm2019/pictures/attributes2.PNG")

```

## Analysis

- classification model tested
- which ones are more adapted to the problem

## Results

- show results, ac-curacies
- recommendations and implementations



<!-- ## Source of data -->

<!-- - where the data comes from -->
<!-- - quick description of the data -->


<!-- # Data processing -->

<!-- - explain the purpose of data cleaning -->
<!-- - why it is so important in data analytic -->


## Loading data


The data has  been provided in a csv format. As stated before, the file contrains 512 ponservations. The imported file has been saved in a variable named "bands". The next part focuses on data description, in order to gather and understand as much insights about the variables as possible. This is a very important step before plinging into  the model creation, as it allows the user to familariaze itself with the data set, 
```{r}
bands <- read.csv2(file = here('bands3.csv'), sep = ';',na.strings = "?")
```


## Data visualization

The first task to analyze a dataset is to inspect all the variables and their values. In order to do that, the 'str' was applied and the results are showed here below.

```{r str, echo=FALSE, fig.cap= 'Figure 1', fig.align='center'}
str(bands)
```

It can be noticed that during import, the sytsem classified some numeric variables as factors. In this respect, a transformation  will be performed in order to correct the missclassification. Furthermore, the data are not recorded in a consistent way for all the observations: part of inputs  are in upper cases and some are in lower cases. This can occur when  different people are in charge to record the data or it could be related to the different practices among  the locations from where the data comes from. This problem can lead to a bad data perception, so it has been decided to trasnform all categorical data to upper cases. 

In addition. it has been observed that some nominal variables are characterized by  a high number of levels, which means that they will not be really useful for a potential classification task. At this stage, no transformation will be performed regarding this matter, but the subject will be rediscssed further in the report.

At the same time, variables with only one level don't bring any information for the classification, so they will be removed from the dataset. 

It has already become clear at this stage that this dataset needs to be cleaned before analysing it.


### Standardization of the dataset

The first transformation is realated to the misclassification mentioned above (numeric variables classified as factors) and the transformation of the categorical variables to uppcarecase, so that the data is consistent.

```{r standardization, message=FALSE, warning=FALSE, include=FALSE}


#change class to numeric for numeric variables 
cols_numeric = c(21:39)  
bands[,cols_numeric] = apply(bands[,cols_numeric], 2, function(x) as.numeric(as.character(x))) 

# uppercase for all the factor values
bands <- as.data.frame(lapply(bands,function(x) 
  if(is.factor(x)) factor(toupper(x)) 
  else(x)))


```


```{r}
table(bands$band_type)

# Dataset of only 1s
bands.bands = bands[bands$band_type == "BAND",]

# Dataset with only 0s
bands.nobands = bands[bands$band_type == "NOBAND",]

# Preparing random samples for training and test set allocation
bands.nobands.sample <- bands.nobands[sample(x=1:nrow(bands.nobands),size = nrow(bands.bands)),]

# Combine the above 2 datasets
bands.sample <- rbind(bands.bands, bands.nobands.sample)

bands.sample <- knnImputation(bands.sample, k = 22)
anyNA(bands.sample)

bands.sample <-
  bands.sample[, which(
    !names(bands.sample) %in% c(
      "date", # useless
      "ink_color", # only 1 level
      "customer", # don't depend on the printing processus
      'cylinder_division', # only 1 level
      'job_number' # too many levels
    )
  )]

bands.sample$cylinder_no <- as.factor(substr(bands.sample$cylinder_no, 0, 1))
```




Here below is an overview of the dataset.


```{r datatable, echo=FALSE, message=FALSE, warning=FALSE, fig.cap= 'Figure 2: Datatable', fig.align='center'}
kable(bands, 'html') %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
   scroll_box(width = "100%", height = "400px")
```

## Missing values

The next step is having a closer look at the missing variables. First the 'plot_intro'  and 'plot_na' functions were used to have a global viw of the status of the variables.


```{r echo=FALSE, message=FALSE, warning=FALSE, fig.cap= 'Figure 3',fig.align='center'}
# bands %>% 
#   introduce() %>%
#   t()%>%
#   kable() %>%
#   kable_styling(bootstrap_options = c("striped", "hover","condensed","bordered"),full_width = F, position = "center")

plot_intro(bands)

```

It can be observed  from Figure 3, that 4.6 % of the data is missing and the complete rows(i.e. an observation containing a value for all the variables)  represents only 51 % of the total observations.

```{r percentage na, fig.cap= 'Figure 4: Prevalence of NAs', fig.align='center'}

x<-inspect_na(bands)
show_plot(x, col_palette=2)
```
Figure 4 shows that all the 'NAs' of the bands dataset come from a total of  28 variables, with a special mention for the **location** variables which counts 156 missing values (almost 30 % percent of the observations are missing). Then, a total of  10 variables have the same amount of missing values (an average of 57) that account for 10% of the observatios in each attribute. The repeating patterns drives to a further analysis of the missing values, which was performed in the falowing part.

### Structure of the missing values

As stated before, to investigate the findings mentioned above related to the identical pourcentage of missing values, another  plot  was proposed to have a better look at the distribution of missing values. Having said that, the  graph below represents the missing values per variable per row. 

```{r structure of NAs, echo=FALSE, message=FALSE, warning=FALSE, fig.cap= 'Figure 5: Missing values in rows', fig.align='center'}


row.plot <- bands %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
    geom_raster(alpha=0.8) +
    scale_fill_manual(name = "",
        values = c('steelblue', 'tomato2'),
        labels = c("Present", "Missing")) +
    labs(x = "Variable",
           y = "Row Number", title = "Missing values in rows") +
    coord_flip()

row.plot
```

Figure 5 is confirming the intuition preveiously stated. The repartition of missing values seems to be concentrated in the very last observations for several variables. This indicates that chuncks of consecutive values are missing. This could be due to a problem in recording the observations, or more simply due to the fact that from a certain point in time, they decided  not to record these specific variables anymore. 

For a total of 13 variables, information is missing starting the 486th observation, which means that information is lost on the respective variables. This raises the question of weather it is useful to keep these observations for the analysis; deleting them would reduce the dataset of 54 rows but would also reduce drastically the number of missing values that we don't have to replace by an imputation method (knn, mean, median...). Keeping them and replacing the missing values for the 13 variables by an imputation method would not make any sense as more than 30 % of the variables in the observations are created from assumptions (13 out 40). Based on this point, we decide to delete the last 54 consecutive observations of the dataset, which will give us a dataset with 485 observations. 

```{r delete last obs, message=FALSE, warning=FALSE}
#Delete the last rows that have consecutive missing data
bands1 <- bands[-c(486:540),]
```


At this point, we can check again the prevalence of missing values: 

```{r percentage na 2, fig.cap= 'Figure 4: Prevalence of NAs'}

x1<-inspect_na(bands1)
show_plot(x1, col_palette=2)

bands1 %>%
  introduce() %>%
  t() %>%
  kable() %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "bordered"),
    full_width = F,
    position = "center") 
```

We observe that the variable **location** is the only one to still have an important ratio of missing values (more than 20%). Replacing all these values with an imputation method don't seem to be the best option in our opinion. We take the decision to set these NAs as **UNDEFINED** to ....


```{r location}
# replace missing values of "location variable" with value "Undefined"
bands1$location = as.character(bands1$location)
bands1$location[is.na(bands1$location)] <- "UNDEFINED"
bands1$location = as.factor(bands1$location)

```


### Imputation of the missing values

The amount of missing values for the rest of the variables is perceived as acceptable and these variables will be imputed by a **k-Nearest-Neighbors** (kNN) method. KNN is an algorithm that is useful for matching a point with its closest k neighbors in a multi-dimensional space. It can be used for data that are continuous, discrete, ordinal and categorical which makes it particularly useful for dealing with all kind of missing data. We have to set a value for **k** and decide to go for the simple approach to set k = sqrt(n) = 22. 

```{r}
# replace missing values with knn 


n <- nrow(bands1)
n
k <- sqrt(n)
k

bands1 <- knnImputation(bands1, k=22)

# check missing value
anyNA(bands)
```

## Selection of the variables

### First elimination

- look at the variable
- some are useless
- cylinder_no special
too many levels but we can keep the first letter as value (the same letter comes from same fabrication so maybe same problem)

Once the database is complete and has no more missing values, we have now to look at these variables and decide what are the one we can delete for the analysis. In fact, there are a lot of attributes that are useless to define if the product presents defects or not. First of all, we can delete the variable with only 1 level of factor like **ink_color** and **cylinder_division**, as they won't have any effect on the response variable. on the other hand, the variable **job_number** seems to have too much levels (more than 200) and don't seem to affect the response variable. The variables **customer** and **date** can also be deleted as it have no possibiliies to affect the classe of the observations. Finally, the variable **cylinder_no** recquire a deeper analysis: if we look at the number of levels we should delete it, because it has almost the same number of levels (429) than observations (485) and it doesn't make sense to keep it to define the class. Therefore, the cylinder is the most important part of the printing processus, as when a problem of banding is detected in the processus, the cylinder has to be removed and repaired. So that means that it has a direct effect on the response variable. We really want to keep it for the analysis, so we decide to keep only the first letter of the value for each colomn, as we see that almost every values is in the form "LETTER NUMBER NUMBER NUMBER"; doing so the number of levels drop to 17, which is acceptable in term of analysis. We can assume that the letter represent the number of the batch or the location where it has been produced and it could have real effect on the response variable. 

This first attempt to reduce the number of attribute gives us a database with 35 variables, which seems still high for a good analysis. We will see another method based on statistical features to try to select the most important attributes to keep for the analysis. 

```{r delete var}
# Delete variables that are not needed
bands1 <-
  bands1[, which(
    !names(bands1) %in% c(
      "date", # useless
      "ink_color", # only 1 level
      "customer", # don't depend on the printing processus
      'cylinder_division', # only 1 level
      'job_number' # too many levels
    )
  )]

bands1$cylinder_no <- as.factor(substr(bands1$cylinder_no, 0, 1))
```



<!-- ```{r} -->
<!-- bands %>% -->
<!--   introduce() %>% -->
<!--   t() %>% -->
<!--   kable() %>% -->
<!--   kable_styling( -->
<!--     bootstrap_options = c("striped", "hover", "condensed", "bordered"), -->
<!--     full_width = F, -->
<!--     position = "center")  -->


<!-- summary(bands) %>% -->
<!--   kable() -->

<!-- plot_intro(bands) -->

<!-- bands %>%  -->
<!--   explore::describe() %>% -->
<!--   kable() %>% -->
<!--   kable_styling(bootstrap_options = c("striped", "hover","condensed","bordered"),full_width = F, position = "center") -->

<!-- ``` -->


### Boruta test - Second elimination


The Boruta algorithm is a wrapper built around the random forest classification algorithm. It tries to capture all the important and interesting features we might have in our dataset with respect to an outcome variable.
We can explain how the algorithm works with help of this [website](https://www.r-bloggers.com/feature-selection-with-the-boruta-algorithm/).

Let’s assume we have a target vector T (the response variable **band_type**) and a bunch of predictors P (all the other variables).

The Boruta algorithm starts by duplicating every variable in P, but instead of making a row-for-row copy, it permutes the order of the values in each column. So, in the copied columns (let’s call them P’), there should be no relationship between the values and the target vector.

Boruta then trains a Random Forest to predict T based on P and P’.

The algorithm then compares the variable importance scores for each variable in P with it’s “shadow” in P’. If the distribution of variable importances is significantly greater in P than it is in P’, then the Boruta algorithm considers that variable significant. 


```{r message=FALSE, warning=FALSE, include=FALSE}


boruta_test <- Boruta(band_type ~ ., data = bands.sample, doTrace = 2)
table_result <- as.data.frame(boruta_test$finalDecision)
setDT(table_result, keep.rownames = TRUE)[]
colnames(table_result) <- c("Variable", "Decision")

kable(table_result) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "bordered"),
    full_width = F,
    position = "center"
  ) %>%
  footnote(symbol = strwrap("Results of the boruta test")) %>%
  scroll_box(width = "500px", height = "300px")


variables_to_keep <- table_result %>%
  filter(table_result$Decision == 'Confirmed' |
           table_result$Decision == 'Tentative')

band_typeVar <- data.frame('band_type', 'Confirmed')
names(band_typeVar) <- c('Variable', 'Decision')

variables_to_keep <- rbind(variables_to_keep, band_typeVar)

names_variables_to_keep <- variables_to_keep$Variable

names_variables_to_keep

bands.sample <-
  bands.sample[, which(
    names(bands.sample) %in% names_variables_to_keep
  )]

```



```{r plot boruta, echo=FALSE, fig.align='center', fig.cap='Importance of variable with Boruta'}
plot(boruta_test, xlab = "", xaxt = "n")
lz <- lapply(1:ncol(boruta_test$ImpHistory), function(i)
  boruta_test$ImpHistory[is.finite(boruta_test$ImpHistory[, i]), i])
names(lz) <- colnames(boruta_test$ImpHistory)
Labels <- sort(sapply(lz, median))
axis(
  side = 1,
  las = 2,
  labels = names(Labels),
  at = 1:ncol(boruta_test$ImpHistory),
  cex.axis = 0.8
)
```

The results of the Boruta algorithm are shown in this plot, with the importance of each variables and the final decision to keep it or not. The first thing we observe is that there are a lot of important variables but some are more than others, specially the right hand side of the elbow. Then we notice that the in the 12 most important variables, only one (**grain_screened**) is impacted by the problem of the last 54 observations presenting only missing values. Running the Boruta algorithm on the database with the 485 observations makes sense, as the objectif is to spot which variables are the most important and it is better to do it on a database which reflects the most the reality, limiting the missing values. 

The decision is to keep the 11 most important variables according to Boruta, excluding the variables having consecutive missing values in the last observations, which is **grain_screened**.


```{r}

bands2 <- bands[, which(
    names(bands) %in% c(
      "press_type", 
      "press", 
      "press_speed", 
      'ink_type', 
      'viscosity',
      'cylinder_no',
      'hardener',
      'cylinder_size',
      'roller_durometer',
      'cylinder_type',
      'band_type'
    )
  )]

bands2$cylinder_no <- as.factor(substr(bands2$cylinder_no, 0, 1))

bands2 <-  knnImputation(bands2, k=22)


bands3 <- bands1[, which(
    names(bands1) %in% c(
      "press_type", 
      "press", 
      "press_speed", 
      'ink_type', 
      'viscosity',
      'cylinder_no',
      'hardener',
      'cylinder_size',
      'roller_durometer',
      'cylinder_type',
      'band_type'
    )
  )]

bands3$cylinder_no <- as.factor(substr(bands3$cylinder_no, 0, 1))



# Dataset of only 1s
bands2.bands = bands2[bands2$band_type == "BAND",]

# Dataset with only 0s
bands2.nobands = bands2[bands$band_type == "NOBAND",]

# Preparing random samples for training and test set allocation
bands2.nobands.sample <- bands2.nobands[sample(x=1:nrow(bands2.nobands),size = nrow(bands2.bands)),]

# Combine the above 2 datasets
bands2.sample <- rbind(bands2.bands, bands2.nobands.sample)


```


<!-- ```{r confirmed variable, echo=FALSE, fig.align='center', fig.cap= 'Table of the final decision of Boruta'} -->
<!-- kable(table_result) %>% -->
<!--   kable_styling( -->
<!--     bootstrap_options = c("striped", "hover", "condensed", "bordered"), -->
<!--     full_width = F, -->
<!--     position = "center" -->
<!--   ) %>% -->
<!--   footnote(symbol = strwrap("Results of the boruta test")) %>% -->
<!--   scroll_box(width = "500px", height = "300px") -->
<!-- ``` -->


## Outliers

We have generated the boxplot and the summary for all the variables and examinated the outliers. Given that the outliers were not showing any significant values, we have decided that there are no error meassurements and neither error entries in the data.

```{r, message=FALSE, warning=FALSE, include= FALSE}

numeric_column <- names(select_if(bands, is.numeric))

for (i in numeric_column) {
  print(summary(bands[i]))
  print (boxplot(bands[i])$out)
}

```


# Exploratory Data Analysis

- find an order for the different plot that make sense
- do not put a plot if it is not useful
- get insights

```{r fig.height= 12}


plot_histogram(bands)

plot_density(bands)



plot_boxplot(bands, by= 'band_type',  ncol = 2, title = "Side-by-side boxplots")

# split data in 2
bands.band <- filter(bands, bands$band_type == 'BAND')

bands.noband <- filter(bands, bands$band_type == 'NOBAND')


```

```{r, fig.width = 10, fig.height = 20}


bands%>%
  explore_all(target = band_type)
```







# Fitting the models


```{r}
#normalize data
# doesn't change the results so we will not keep the modifications
# b.process <- preProcess(bands, method= 'range')
# b <- predict(b.process, newdata = bands)
```


## test and train sets
```{r}


# Create the training and test datasets
set.seed(100)

# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(bands.sample$band_type, p=0.75, list=FALSE)

# Step 2: Create the training  dataset
trainData <- bands.sample[trainRowNumbers,]

# Step 3: Create the test dataset
testData <- bands.sample[-trainRowNumbers,]

# the proportion of the classes (BAND and NOBAND) stay the same in the train and test set (65 and 35% respectively)

```



<!-- ```{r} -->
<!-- # MARS Multivariate Adaptive Regression Splines -->
<!-- # recursive feature elimination (RFE) -->
<!-- set.seed(100) -->
<!-- options(warn = -1) -->

<!-- subsets <- c(1:6, 10, 15, 35) -->

<!-- ctrl <- rfeControl( -->
<!--   functions = rfFuncs, -->
<!--   method = "repeatedcv", -->
<!--   repeats = 5, -->
<!--   verbose = FALSE -->
<!-- ) -->

<!-- lmProfile <- rfe( -->
<!--   x = trainData, -->
<!--   y = trainData$band_type, -->
<!--   sizes = subsets, -->
<!--   rfeControl = ctrl -->
<!-- ) -->

<!-- lmProfile -->


<!-- # Set the seed for reproducibility -->
<!-- set.seed(100) -->

<!-- # Train the model using randomForest and predict on the training data itself. -->
<!-- model_mars = train(band_type ~ ., data = trainData, method = 'earth') -->
<!-- fitted <- predict(model_mars) -->
<!-- varimp_mars <- varImp(model_mars) -->
<!-- plot(varimp_mars, main = "Variable Importance with MARS") -->


<!-- model_mars -->

<!-- predicted <- predict(model_mars, testData) -->
<!-- predicted -->

<!-- confusionMatrix( -->
<!--   reference = testData$band_type, -->
<!--   data = predicted, -->
<!--   mode = 'everything', -->
<!--   positive = 'NOBAND' -->
<!-- ) -->
<!-- ``` -->

## Random Forest

- explain how it works
- fit the model
- results

```{r}
# random forest


# Call the function:

integ_mod_1 <- data_integrity_model(data = bands, model_name = "randomForest")
integ_mod_1$data_ok


# Any errors ?
integ_mod_1

set.seed(12345)
model_rf <- randomForest(formula(band_type ~.),
                          data= trainData,
                          ntree=400, mtry=3,
                          importance=TRUE,
                          localImp=TRUE,
                          na.action=na.roughfix,
                          replace=FALSE)
print(model_rf)

head(round(importance(model_rf), 2))
varImpPlot(model_rf)

rf.pred<-predict(model_rf, testData, type="class")
rf.pred

table(true=testData$band_type, pred = rf.pred)

CrossTable(x=testData$band_type, y=rf.pred, prop.chisq=FALSE)

confusionMatrix(rf.pred, testData$band_type, positive = 'NOBAND')
```



## Nearest Neighbour Classification 

we still have to fit this model


- explain how it works
- fit the model
- results

```{r}

trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
knn_fit <- train(band_type ~., data = trainData, method = "knn",
 trControl=trctrl,
 preProcess = c("center", "scale"),
 tuneLength = 10)

knn_fit

test_pred_knn <- predict(knn_fit, newdata = testData)

confusionMatrix(test_pred_knn, testData$band_type)
```



## Logistic Regression

- explain how it works
- fit the model
- results


```{r}
# logistic regression

fitControl <- trainControl(method = "none")

model_lr <-
  train(band_type ~ .,
        data = trainData,
        method = "glm",
        trControl = fitControl)

print(model_lr$finalModel)

pred <- predict(model_lr, newdata = testData)

print(table(pred))

mat <-
  confusionMatrix(data = pred,
                  reference = testData$band_type,
                  positive = "NOBAND")
print(mat)

# the results are very poor, so we will focus on other model, because this one would be difficult to improve

```

## Support Vector Machine 1

- explain how it works
- fit the model
- results


```{r}
# SVM1

fitControl <- trainControl(method = "cv", number = 5)

model_svm <- train(
  band_type ~ .,
  data =
    trainData,
  method = "svmLinear",
  trControl = fitControl,
  tuneGrid = data.frame(C = 10)
)
print(model_svm)

varimp_svm <- varImp(model_svm)
varimp_svm
plot(varimp_svm, main = "Variable Importance with SVM")


print(confusionMatrix(
  data = predict(model_svm, newdata =
                   testData),
  reference = testData$band_type,
  positive = "NOBAND"
))




```

## Support Vector Machine 2

- explain how it works
- fit the model
- results

```{r}
#SVM2


model_svm2 <- train(band_type ~ .,
                          data = trainData, 
                          method = "svmRadialCost",
                          preProcess = "range",
                          trace = FALSE,
                          trControl = trainControl(method = "repeatedcv", number = 10, repeats = 10, 
                                                  verboseIter = FALSE))
model_svm2

plot(model_svm2)

print(confusionMatrix(
  data = predict(model_svm2, newdata =
                   testData),
  reference = testData$band_type,
  positive = "NOBAND"
))



# # this one takes a lot of time
# C <- c(0.25, 0.1, 0.5, 1)
# sigma <- c(0.01, 0.1, 1)
# gr.radial<-expand.grid(C = C, sigma = sigma)
# 
# model_svm3<- train(band_type ~ .,
#                           data = trainData,
#                           method = "svmRadial",
#                           preProcess = "range",
#                           trace=FALSE,
#                           trControl = trainControl(method = "repeatedcv", number = 10, repeats = 5, 
#                                                   verboseIter = FALSE),
#                           tuneGrid=gr.radial)
# 
# 
# model_svm3
# 
# plot(model_svm3)
# 
# print(confusionMatrix(
#   data = predict(model_svm3, newdata =
#                    testData),
#   reference = testData$band_type,
#   positive = "NOBAND"
# ))
```


## Neural Network

- explain how it works
- fit the model
- results

```{r neural network model}

# numFolds <-
#   trainControl(
#     method = 'cv',
#     number = 1,
#     classProbs = TRUE,
#     verboseIter = TRUE,
#     summaryFunction = twoClassSummary,
#     preProcOptions = list(
#       thresh = 0.75,
#       ICAcomp = 3,
#       k = 5
#     )
#   )
# fit2 <-
#   train(
#     band_type ~ . - band_type,
#     data = trainData,
#     method = 'nnet',
#     preProcess = c('center', 'scale'),
#     trControl = numFolds,
#     tuneGrid = expand.grid(size = c(10), decay = c(0.1))
#   )




model_nnet <- caret::train(band_type ~ ., data = trainData, method = "nnet", preProcess = "range", 
    trace = FALSE, trControl = trainControl(method = "cv"))

model_nnet

varimp_nnet <- varImp(model_nnet)
varimp_nnet
plot(varimp_nnet, main = "Variable Importance with Nnet")

results1 <- predict(model_nnet, newdata = testData)
results1

conf1 <-
  confusionMatrix(results1, testData$band_type, positive = 'NOBAND')
conf1



```

## Classification Tree

- explain how it works
- fit the model
- pruning...
- results

```{r}

library(rpart)
library(rpart.plot)
# Build the model
set.seed(123)
model_cart <- rpart(band_type ~., data = trainData, method = "class")  
model_cart
summary(model_cart)

# pruning
par(pty = "s")
with(model_cart, plot(cptable[, 3], xlab = "Tree Number", ylab = "Resubstitution Error (R)", 
    type = "b"))

# Plot the trees
rpart.plot(model_cart, box.palette = "RdBu", nn = FALSE)

printcp(model_cart)


#pruning
cart_prune <- prune(model_cart, cp = 0.01)



cart.pred<-predict(model_cart, testData, type="class")
cart.pred

table(true=testData$band_type, pred = cart.pred)

CrossTable(x=testData$band_type, y=cart.pred, prop.chisq=FALSE)

confusionMatrix(cart.pred, testData$band_type, positive = 'NOBAND')

predict_cart <- predict(model_cart, newdata = testData)


```

## Linear Discriminant Analysis

- explain how it works
- fit the model
- results

```{r}

# # linear discriminant analysis
# 
# trainDataLda <- trainData[, -c(18)]
# testDataLda <- testData[, -18]
# 
# # Estimate preprocessing parameters
# preproc.param <- trainDataLda %>% 
#   preProcess(method = c("center", "scale"))
# # Transform the data using the estimated parameters
# train.transformed <- preproc.param %>% predict(trainDataLda)
# test.transformed <- preproc.param %>% predict(testDataLda)
# 
# 
# 
# library(MASS)
# # Fit the model
# model_lda <- lda(band_type ~., data = train.transformed)
# # Make predictions
# predictions <- model_lda %>% predict(test.transformed)
# # Model accuracy
# mean(predictions$class==test.transformed$band_type)
# 
# model_lda
# plot(model_lda)

# lda.data <- cbind(train.transformed, predict(model_lda)$x)
# ggplot(lda.data, aes(LD1, LD2)) +
#   geom_point(aes(color = band_type))
```








