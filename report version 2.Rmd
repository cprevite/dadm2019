--- 
title: 'Report: Data Analytics for Decision Making'
author: "Claudio Previte and Ana -Maria Casian"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: TRUE
    toc_float:
      collapsed: true
      smooth_scroll: true
    fig_caption: yes
---



```{r message=FALSE, warning=FALSE}
library(here)
library(Hmisc)
library(dplyr)
library(DataExplorer)
library(ggplot2)
library(lattice)
library(inspectdf)
library(kableExtra)
library(explore)
library(DT)
library(dplyr)
library(Boruta)
library(corrr)
library(tidyverse)
library(caret)
library(randomForest)
library(funModeling)
library(gmodels)
library(data.table)

```



# Executive summary

## Challenges

- describe the problem
- describe the dataset
- response variable

## Analysis

- classification model tested
- which ones are more adapted to the problem

## Results

- show results, accuracies
- recommendations and implementations


# General

- purpose of the course
- the benefit of Machine Learning in general

## Source of data

- where the data comes from
- quick description of the data


## Case description

- describe the problem
- benefit of Machine Learning in this special case

# Data processing

- explain the purpose of data cleaning
- why it is so important in data analytics


## Loading data
- 

```{r}
bands <- read.csv2(file = here('bands3.csv'), sep = ';',na.strings = "?")
```


## Data visualization

The first task to analyze a dataset is to have a look at all the variables and their values. 

```{r str, echo=FALSE, fig.cap= 'Figure 1'}
str(bands)
```

We notice that there are some numerical and nominal attributes. To be precise, 20 numerical variables and 19 nominal variables, including the response variable, band_type. There are some nominal variables with a high number of levels, which means that they will not be really useful for a potential classification task; we will see further what to do with these ones. On the other hand, variables with only one level will be deleted, because they don't bring any information for the classification. We notice also that the dataset is not standardized, which means that the value are not recorded the same way depending on the observations; it appears that sometimes, the values are in lower cases and sometimes in upper cases, so we have to standardize it to get real insights from the data. Important informations comes from the missing values, which are numerous. We will discuss also further what to do with these ones. 

As we were aware, this dataset needs a lot of cleaning before to be analyzed.

### Standardization of the dataset

As seen before, the data are not recorded in the same way for all the observations. Some observations are in upper cases and some are in lower cases. This can occur when many different people are in charge to record the data or depending the location where the observations comes from. This problem can lead to a bad data perception, so we decided to put all the values in upper cases. 

```{r standardization, message=FALSE, warning=FALSE, include=FALSE}


#change class to numeric for numeric variables 
cols_numeric = c(21:39)  
bands[,cols_numeric] = apply(bands[,cols_numeric], 2, function(x) as.numeric(as.character(x))) 

# uppercase for all the factor values
bands <- as.data.frame(lapply(bands,function(x) 
  if(is.factor(x)) factor(toupper(x)) 
  else(x)))


```

Here is an overview of the dataset:

```{r datatable, echo=FALSE, message=FALSE, warning=FALSE, fig.cap= 'Figure 2: Datatable'}
datatable(bands)
```

## Missing values

We will focus now on the missing values, which makes this dataset so special. In fact we observe a lot of missing value and we have to decide what to do with them. 

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.cap= 'Figure 3'}
# bands %>% 
#   introduce() %>%
#   t()%>%
#   kable() %>%
#   kable_styling(bootstrap_options = c("striped", "hover","condensed","bordered"),full_width = F, position = "center")

plot_intro(bands)

```

We see from Figure 3, that 4.6 % of the data are missing and the complete rows, i.e. an observation containing a value for all the variables, represent only 51 % of the total observations. From Figure 4, we observe that all the NAs of the bands dataset comes from 28 variables, with a special mention for the **location** variables which counts 156 missing values (almost 30 % percent of the observations are missing). Then, almost 10 variables counts quite the same number of missing value, so we will try to understand if there is a explanation behind this. It should be noted that for these attributes, the percentage of NAs is almost 10 %.  

```{r percentage na, fig.cap= 'Figure 4: Prevalence of NAs'}

x<-inspect_na(bands)
show_plot(x, col_palette=2)
```


### Structure of the missing values

In order to analyze the structure of the missing values, we plot them in rows; that will allow to see if there is a link between the NAs. 

```{r structure of NAs, echo=FALSE, message=FALSE, warning=FALSE, fig.cap= 'Figure 5: Missing values in rows'}


row.plot <- bands %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
    geom_raster(alpha=0.8) +
    scale_fill_manual(name = "",
        values = c('steelblue', 'tomato2'),
        labels = c("Present", "Missing")) +
    labs(x = "Variable",
           y = "Row Number", title = "Missing values in rows") +
    coord_flip()

row.plot
```

We get some interesting informations from Figure 5; the repartition of missing values seems to be concentrated in the very last observations. This could be due to a problem in recording the observations, or more simply due to the fact that from a certain point in time, they decided to not record these specific variables anymore. 13 variables are missing from the 486th observation, which means that we lost a lot of informations. We have to wonder if it is useful to keep these observations for the analysis; deleting them would reduce the dataset of 54 rows but would also reduce drastically the number of missing values that we don't have to replace by an imputation method (knn, mean, median...). Keeping them and replacing the missing values for the 13 variables by an imputation method would make any sense as more than 30 % of the variables in the observations are created from assumptions (13 out 40). Based on this point, we decide to delete the last 54 consecutive observations of the dataset, which will give us a dataset with only 485 observations. 

```{r delete last obs, message=FALSE, warning=FALSE}
#Delete the last rows that have consecutive missing data
bands <- bands[-c(486:540),]
```


At this point, we can check again the prevalence of missing values: 

```{r percentage na 2, fig.cap= 'Figure 4: Prevalence of NAs'}

x1<-inspect_na(bands)
show_plot(x1, col_palette=2)

bands %>%
  introduce() %>%
  t() %>%
  kable() %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "bordered"),
    full_width = F,
    position = "center") 
```

- except for location
consecutive missing -> we take them but set as undefined
- na for other variables is acceptable 
- we will use knn for imputation



```{r location}
# replace missing values of "location variable" with value "Undefined"
bands$location = as.character(bands$location)
bands$location[is.na(bands$location)] <- "UNDEFINED"
bands$location = as.factor(bands$location)

```


### Imputation of the missing values

- describe knn
- why it is better than mean

```{r}
# replace missing values with knn 
# we have to decide if we want to reÃ¨lace only factor or all variables with this method...
library(DMwR)

bands <- knnImputation(bands, k=10)

# check missing value
anyNA(bands)
```

## Selection of the variables

### First elimination

- look at the variable
- some are useless
- cylinder_no special
too many levels but we can keep the first letter as value (the same letter comes from same fabrication so maybe same problem)

```{r delete var}
# Delete variables that are not needed
bands <-
  bands[, which(
    !names(bands) %in% c(
      "date", # useless
      "ink_color", # only 1 level
      "customer", # don't depend on the printing processus
      'cylinder_division', # only 1 level
      'job_number' # too many levels
    )
  )]

bands$cylinder_no <- as.factor(substr(bands$cylinder_no, 0, 1))
```



<!-- ```{r} -->
<!-- bands %>% -->
<!--   introduce() %>% -->
<!--   t() %>% -->
<!--   kable() %>% -->
<!--   kable_styling( -->
<!--     bootstrap_options = c("striped", "hover", "condensed", "bordered"), -->
<!--     full_width = F, -->
<!--     position = "center")  -->


<!-- summary(bands) %>% -->
<!--   kable() -->

<!-- plot_intro(bands) -->

<!-- bands %>%  -->
<!--   explore::describe() %>% -->
<!--   kable() %>% -->
<!--   kable_styling(bootstrap_options = c("striped", "hover","condensed","bordered"),full_width = F, position = "center") -->

<!-- ``` -->


### Boruta test - Second elimination

- objective of boruta
- explain how it works
- justify selected parameter 
- decision to keep only the variable choosen by boruta
- quick summary of new database after cutting the variables

```{r}


boruta_test <- Boruta(band_type ~ ., data = bands, doTrace = 2)
table_result <- as.data.frame(boruta_test$finalDecision)
setDT(table_result, keep.rownames = TRUE)[]
colnames(table_result) <- c("Variable", "Decision")

kable(table_result) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "bordered"),
    full_width = F,
    position = "center"
  ) %>%
  footnote(symbol = strwrap("Results of the boruta test")) %>%
  scroll_box(width = "500px", height = "300px")


plot(boruta_test, xlab = "", xaxt = "n")
lz <- lapply(1:ncol(boruta_test$ImpHistory), function(i)
  boruta_test$ImpHistory[is.finite(boruta_test$ImpHistory[, i]), i])
names(lz) <- colnames(boruta_test$ImpHistory)
Labels <- sort(sapply(lz, median))
axis(
  side = 1,
  las = 2,
  labels = names(Labels),
  at = 1:ncol(boruta_test$ImpHistory),
  cex.axis = 0.8
)


variables_to_keep <- table_result %>%
  filter(table_result$Decision == 'Confirmed' |
           table_result$Decision == 'Tentative')

band_typeVar <- data.frame('band_type', 'Confirmed')
names(band_typeVar) <- c('Variable', 'Decision')

variables_to_keep <- rbind(variables_to_keep, band_typeVar)

names_variables_to_keep <- variables_to_keep$Variable

names_variables_to_keep

bands <-
  bands[, which(
    names(bands) %in% names_variables_to_keep
  )]

```


## Outliers

We have generated the boxplot and the summary for all the variables and examinated the outliers. Given that the outliers were not showing any significant values, we have decided that there are no error meassurements and neither error entries in the data

```{r, message=FALSE, warning=FALSE, include= FALSE}

numeric_column <- names(select_if(bands, is.numeric))

for (i in numeric_column) {
  print(summary(bands[i]))
  print (boxplot(bands[i])$out)
}

```


# Exploratory Data Analysis

- find an order for the different plot that make sense
- do not put a plot if it is not useful
- get insights

```{r fig.height= 12}


plot_histogram(bands)

plot_density(bands)



plot_boxplot(bands, by= 'band_type',  ncol = 2, title = "Side-by-side boxplots")

# split data in 2
bands.band <- filter(bands, bands$band_type == 'BAND')

bands.noband <- filter(bands, bands$band_type == 'NOBAND')


```

```{r, fig.width = 10, fig.height = 20}


bands%>%
  explore_all(target = band_type)
```







# Fitting the models


```{r}
#normalize data
# doesn't change the results so we will not keep the modifications
# b.process <- preProcess(bands, method= 'range')
# b <- predict(b.process, newdata = bands)
```


## test and train sets
```{r}

# Create the training and test datasets
set.seed(100)

# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(bands$band_type, p=0.75, list=FALSE)

# Step 2: Create the training  dataset
trainData <- bands[trainRowNumbers,]

# Step 3: Create the test dataset
testData <- bands[-trainRowNumbers,]
```



<!-- ```{r} -->
<!-- # MARS Multivariate Adaptive Regression Splines -->
<!-- # recursive feature elimination (RFE) -->
<!-- set.seed(100) -->
<!-- options(warn = -1) -->

<!-- subsets <- c(1:6, 10, 15, 35) -->

<!-- ctrl <- rfeControl( -->
<!--   functions = rfFuncs, -->
<!--   method = "repeatedcv", -->
<!--   repeats = 5, -->
<!--   verbose = FALSE -->
<!-- ) -->

<!-- lmProfile <- rfe( -->
<!--   x = trainData, -->
<!--   y = trainData$band_type, -->
<!--   sizes = subsets, -->
<!--   rfeControl = ctrl -->
<!-- ) -->

<!-- lmProfile -->


<!-- # Set the seed for reproducibility -->
<!-- set.seed(100) -->

<!-- # Train the model using randomForest and predict on the training data itself. -->
<!-- model_mars = train(band_type ~ ., data = trainData, method = 'earth') -->
<!-- fitted <- predict(model_mars) -->
<!-- varimp_mars <- varImp(model_mars) -->
<!-- plot(varimp_mars, main = "Variable Importance with MARS") -->


<!-- model_mars -->

<!-- predicted <- predict(model_mars, testData) -->
<!-- predicted -->

<!-- confusionMatrix( -->
<!--   reference = testData$band_type, -->
<!--   data = predicted, -->
<!--   mode = 'everything', -->
<!--   positive = 'NOBAND' -->
<!-- ) -->
<!-- ``` -->

## Random Forest

- explain how it works
- fit the model
- results

```{r}
# random forest


# Call the function:

integ_mod_1 <- data_integrity_model(data = bands, model_name = "randomForest")
integ_mod_1$data_ok


# Any errors ?
integ_mod_1

set.seed(12345)
model_rf <- randomForest(formula(band_type ~.), 
                          data= trainData, 
                          ntree=400, mtry=3, 
                          importance=TRUE, 
                          localImp=TRUE,
                          na.action=na.roughfix,
                          replace=FALSE)
print(model_rf)

head(round(importance(model_rf), 2))
varImpPlot(model_rf)

rf.pred<-predict(model_rf, testData, type="class")
rf.pred

table(true=testData$band_type, pred = rf.pred)

CrossTable(x=testData$band_type, y=rf.pred, prop.chisq=FALSE)

confusionMatrix(rf.pred, testData$band_type, positive = 'NOBAND')
```

```{r}
# check RF with bandsSmall --> in my opinion the results are poor (76% accuracy vs 82%)

bandsSmall <- bands[c(1,2,4,6,7,9,12,16,18,23,24,26)] # only the elbow from Boruta and important variable from RF
# Create the training and test datasets
set.seed(100)

# Step 1: Get row numbers for the training data
trainRowNumbersSmall <- createDataPartition(bandsSmall$band_type, p=0.75, list=FALSE)

# Step 2: Create the training  dataset
trainDataSmall <- bandsSmall[trainRowNumbers,]

# Step 3: Create the test dataset
testDataSmall <- bandsSmall[-trainRowNumbers,]

# Call the function:

integ_mod_2 <- data_integrity_model(data = bandsSmall, model_name = "randomForest")
integ_mod_2$data_ok


# Any errors ?
integ_mod_2

model_rf2 <- randomForest(formula(band_type ~.), 
                          data= trainDataSmall, 
                          ntree=500, mtry=4, 
                          importance=TRUE, 
                          localImp=TRUE,
                          na.action=na.roughfix,
                          replace=FALSE)
print(model_rf2)

head(round(importance(model_rf2), 2))
varImpPlot(model_rf2)

rf.pred<-predict(model_rf2, testDataSmall, type="class")
rf.pred

table(true=testDataSmall$band_type, pred = rf.pred)

CrossTable(x=testDataSmall$band_type, y=rf.pred, prop.chisq=FALSE)

confusionMatrix(rf.pred, testDataSmall$band_type, positive = 'NOBAND')
```


## Nearest Neighbour Classification 

we still have to fit this model

- explain how it works
- fit the model
- results

## Logistic Regression

- explain how it works
- fit the model
- results


```{r}
# logistic regression

fitControl <- trainControl(method = "none")

model_lr <-
  train(band_type ~ .,
        data = trainData,
        method = "glm",
        trControl = fitControl)

print(model_lr$finalModel)

pred <- predict(model_lr, newdata = testData)

print(table(pred))

mat <-
  confusionMatrix(data = pred,
                  reference = testData$band_type,
                  positive = "NOBAND")
print(mat)

# the results are very poor, so we will focus on other model, because this one would be difficult to improve

```

## Support Vector Machine 1

- explain how it works
- fit the model
- results


```{r}
# SVM1

fitControl <- trainControl(method = "cv", number = 5)

model_svm <- train(
  band_type ~ .,
  data =
    trainData,
  method = "svmLinear",
  trControl = fitControl,
  tuneGrid = data.frame(C = 10)
)
print(model_svm)

varimp_svm <- varImp(model_svm)
varimp_svm
plot(varimp_svm, main = "Variable Importance with SVM")


print(confusionMatrix(
  data = predict(model_svm, newdata =
                   testData),
  reference = testData$band_type,
  positive = "NOBAND"
))




```

## Support Vector Machine 2

- explain how it works
- fit the model
- results

```{r}
#SVM2


model_svm2 <- train(band_type ~ .,
                          data = trainData, 
                          method = "svmRadialCost",
                          preProcess = "range",
                          trace = FALSE,
                          trControl = trainControl(method = "repeatedcv", number = 10, repeats = 10, 
                                                  verboseIter = FALSE))
model_svm2

plot(model_svm2)

print(confusionMatrix(
  data = predict(model_svm2, newdata =
                   testData),
  reference = testData$band_type,
  positive = "NOBAND"
))



# # this one takes a lot of time
# C <- c(0.25, 0.1, 0.5, 1)
# sigma <- c(0.01, 0.1, 1)
# gr.radial<-expand.grid(C = C, sigma = sigma)
# 
# model_svm3<- train(band_type ~ .,
#                           data = trainData,
#                           method = "svmRadial",
#                           preProcess = "range",
#                           trace=FALSE,
#                           trControl = trainControl(method = "repeatedcv", number = 10, repeats = 5, 
#                                                   verboseIter = FALSE),
#                           tuneGrid=gr.radial)
# 
# 
# model_svm3
# 
# plot(model_svm3)
# 
# print(confusionMatrix(
#   data = predict(model_svm3, newdata =
#                    testData),
#   reference = testData$band_type,
#   positive = "NOBAND"
# ))
```


## Neural Network

- explain how it works
- fit the model
- results

```{r neural network model}

# numFolds <-
#   trainControl(
#     method = 'cv',
#     number = 1,
#     classProbs = TRUE,
#     verboseIter = TRUE,
#     summaryFunction = twoClassSummary,
#     preProcOptions = list(
#       thresh = 0.75,
#       ICAcomp = 3,
#       k = 5
#     )
#   )
# fit2 <-
#   train(
#     band_type ~ . - band_type,
#     data = trainData,
#     method = 'nnet',
#     preProcess = c('center', 'scale'),
#     trControl = numFolds,
#     tuneGrid = expand.grid(size = c(10), decay = c(0.1))
#   )




model_nnet <- caret::train(band_type ~ ., data = trainData, method = "nnet", preProcess = "range", 
    trace = FALSE, trControl = trainControl(method = "cv"))

model_nnet

varimp_nnet <- varImp(model_nnet)
varimp_nnet
plot(varimp_nnet, main = "Variable Importance with Nnet")

results1 <- predict(model_nnet, newdata = testData)
results1

conf1 <-
  confusionMatrix(results1, testData$band_type, positive = 'NOBAND')
conf1



```

## Classification Tree

- explain how it works
- fit the model
- pruning...
- results

```{r}

library(rpart)
library(rpart.plot)
# Build the model
set.seed(123)
model_cart <- rpart(band_type ~., data = trainData, method = "class")  
model_cart
summary(model_cart)

# pruning
par(pty = "s")
with(model_cart, plot(cptable[, 3], xlab = "Tree Number", ylab = "Resubstitution Error (R)", 
    type = "b"))

# Plot the trees
rpart.plot(model_cart, box.palette = "RdBu", nn = FALSE)

printcp(model_cart)


#pruning
cart_prune <- prune(model_cart, cp = 0.01)



cart.pred<-predict(model_cart, testData, type="class")
cart.pred

table(true=testData$band_type, pred = cart.pred)

CrossTable(x=testData$band_type, y=cart.pred, prop.chisq=FALSE)

confusionMatrix(cart.pred, testData$band_type, positive = 'NOBAND')

predict_cart <- predict(model_cart, newdata = testData)


```

## Linear Discriminant Analysis

- explain how it works
- fit the model
- results

```{r}

# linear discriminant analysis

trainDataLda <- trainData[, -18]
testDataLda <- testData[, -18]

# Estimate preprocessing parameters
preproc.param <- trainDataLda %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(trainDataLda)
test.transformed <- preproc.param %>% predict(testDataLda)



library(MASS)
# Fit the model
model_lda <- lda(band_type ~., data = train.transformed)
# Make predictions
predictions <- model_lda %>% predict(test.transformed)
# Model accuracy
mean(predictions$class==test.transformed$band_type)

model_lda
plot(model_lda)

# lda.data <- cbind(train.transformed, predict(model_lda)$x)
# ggplot(lda.data, aes(LD1, LD2)) +
#   geom_point(aes(color = band_type))
```








